{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import os\n",
    "os.chdir('H:/Mes Documents/ServiceCivil2019/schedvisu')\n",
    "import sys\n",
    "sys.path.append('scripts')\n",
    "\n",
    "from scripts.main import load_config, get_day_range\n",
    "from retrieve_data import retrieve_and_save_data_from_PACS\n",
    "from extract_data import load_transform_and_save_data_from_files\n",
    "from create_report import create_report, get_report_type\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set the width of the notebook\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run()\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run the whole pipeline for 4 years, starting by 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "date_ranges = [\n",
    "    {'start': '2019-01-01', 'end': '2019-12-06'},\n",
    "    {'start': '2018-01-01', 'end': '2018-12-31'},\n",
    "    {'start': '2017-01-01', 'end': '2017-12-31'},\n",
    "    {'start': '2016-01-01', 'end': '2016-12-31'}\n",
    "]\n",
    "\n",
    "config = load_config()\n",
    "for date_range in date_ranges:\n",
    "    try:\n",
    "        create_logger()\n",
    "        local_config = deepcopy(config)\n",
    "        local_config['main']['start_date'] = date_range['start']\n",
    "        local_config['main']['end_date'] = date_range['end']\n",
    "        run_pipeline(local_config)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error('Error while running workflow')\n",
    "        logging.error(\"-\"*60)\n",
    "        logging.error(e, exc_info=True)\n",
    "        logging.error(\"-\"*60)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        logging.error('Interrupted by user')\n",
    "\n",
    "    finally:\n",
    "        logging.shutdown()\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_transform_and_save_data_from_files(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the grouping by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_count_series, df_count_studies = do_series_groupby(config, df)\n",
    "display(df_count_series)\n",
    "display(df_count_studies)\n",
    "display(df_count_series.groupby('Machine Group').sum())\n",
    "display(df_count_studies.groupby('Machine Group').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the data (while changing things in the API so the bugs/errors do not appear anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Study Instance UID'].isin(df[df['Institution Name'] == 'Hopital neuchatelois']['Study Instance UID'])]\n",
    "df = df[~df['Study Instance UID'].isin(df[df['Institution Name'] == 'MEDECINE NUCLEAIRE']['Study Instance UID'])]\n",
    "df = df[~df['Study Instance UID'].isin(df[df['Machine'] == '']['Study Instance UID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check why some non-valid institution name went through the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad_series = df[df['Study Instance UID'].isin(df[df['Machine'] == 'Ingenuity TF PET/CT']['Study Instance UID'])]\n",
    "\n",
    "if len(df_bad_series) > 0:\n",
    "    bad_study_UID = list(set(df_bad_series['Study Instance UID'].values))[0]\n",
    "    logging.info('bad_study_UID: ' + bad_study_UID)\n",
    "    \n",
    "    inst_name = list(set([inst_name.replace('  ', ' ') for inst_name in df_bad_series.loc[:, 'Institution Name']]))[0]\n",
    "    logging.info('inst_name: ' + inst_name)\n",
    "    logging.info('accepted_inst_names: ' + str(accepted_inst_names))\n",
    "    logging.info('inst_name is in accepted_inst_names? ' + str(inst_name.lower().replace(' ', '') in accepted_inst_names))\n",
    "    logging.info('date: ' + str(list(set(df_bad_series['Series Date']))[0]))\n",
    "    \n",
    "    df_studies = find_studies_for_day(config, '20191029', ['PT', 'NM'])\n",
    "    df_bad_study = df_studies[df_studies['Study Instance UID'] == bad_study_UID]\n",
    "    df_series = find_series_for_studies(config, df_bad_study)\n",
    "    df_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of having some studies with mixed machine names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a study which has both the millennium and another machine\n",
    "df_series_for_study = df[df['Study Instance UID'].isin(df[df['Machine'] == 'MILLENNIUM MPR']['Study Instance UID'])]\n",
    "df_series_for_study[df_series_for_study['Study Instance UID'].isin(df_series_for_study[df_series_for_study['Machine'] == 'BrightSpeed']['Study Instance UID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug the processing of some unfetchable rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
