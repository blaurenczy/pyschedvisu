{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import holidays\n",
    "from copy import deepcopy\n",
    "import re\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import os\n",
    "os.chdir('H:/Mes Documents/ServiceCivil2019/schedvisu')\n",
    "import sys\n",
    "sys.path.append('scripts')\n",
    "\n",
    "from scripts.main import load_config, get_day_range\n",
    "from retrieve_data import retrieve_and_save_data_from_PACS\n",
    "from extract_data import load_transform_and_save_data_from_files\n",
    "from create_report import create_report, get_report_type\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set the width of the notebook\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the config and get the series using the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "config['main']['start_date'] = '2019-01-07'\n",
    "config['main']['end_date'] = '2019-12-06'\n",
    "df_studies = load_transform_and_save_data_from_files(config)\n",
    "df_studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_studies.groupby(['Machine', 'Description'])['Patient ID'].count()).sort_values(['Machine', 'Patient ID'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studies[df_studies['Description'] == 'OTHER'].groupby(['Machine', 'Study Description'])['Patient ID'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the loading from a main studies.pkl file and expanding it, instead of recreating the file every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) get the already processed studies if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "config['main']['start_date'] = '2019-01-01'\n",
    "config['main']['end_date'] = '2019-01-15'\n",
    "\n",
    "start_date, end_date, days_range = main.get_day_range(config)\n",
    "studies_save_path = 'data/studies.pkl'\n",
    "df_studies = None\n",
    "already_processed_days = []\n",
    "holiday_days = holidays.Switzerland(prov='VD')\n",
    "\n",
    "# check if the data has already been extracted, transformed and saved\n",
    "if os.path.isfile(studies_save_path):\n",
    "    logging.info('Reading studies database: save file found at \"{}\", loading data'.format(studies_save_path))\n",
    "    df_studies = pd.read_pickle(studies_save_path)\n",
    "    already_processed_days = set(df_studies['Date'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) check whether all required days have already been processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_process = [day for day in days_range if day.strftime('%Y%m%d') not in already_processed_days and day.weekday() not in [5, 6] and day not in holiday_days]\n",
    "days_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) process the days that are not present in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in days_to_process:\n",
    "    logging.info('Processing {}: day is required but not present in the main studies DataFrame'.format(day.strftime('%Y%m%d'))\n",
    "\n",
    "    # create a local config object just to process the specified days\n",
    "    local_config = deepcopy(config)\n",
    "    local_config['main']['start_date'] = day.strftime('%Y-%m-%d')\n",
    "    local_config['main']['end_date'] = day.strftime('%Y-%m-%d')\n",
    "                 \n",
    "    # load in the data\n",
    "    df_series = load_data_from_files(local_config)\n",
    "    # mark the rektakes and the machine group for each series\n",
    "    df_series = mark_retakes(local_config, df_series)\n",
    "    df_series = mark_machine_group(local_config, df_series)\n",
    "    # show some info about the series and studies\n",
    "    #show_series_groupby(config, df_series)\n",
    "\n",
    "    # group the series together into a DataFrame of studies\n",
    "    df_studies_for_day = df_series.replace(np.nan, '').groupby('SUID').agg({\n",
    "        'Series Date': lambda x: '/'.join(set(x)),\n",
    "        'Start Time': 'min',\n",
    "        'End Time': 'max',\n",
    "        'Study Description': lambda x: '/'.join(set(x)),\n",
    "        'Patient ID': lambda x: '/'.join(set(x)),\n",
    "        'Machine Group': lambda x: '/'.join(set(x)),\n",
    "        'Modality': lambda x: '/'.join(set(x)),\n",
    "        'Protocol Name': lambda x: '/'.join(set(x))\n",
    "    }).sort_values(['Series Date', 'Start Time', 'Machine Group', 'SUID'])\\\n",
    "    .rename(columns={'Series Date': 'Date'})\n",
    "             \n",
    "    # merge back into the main DataFrame\n",
    "    if df_studies is None:\n",
    "        df_studies = df_studies_for_day\n",
    "    else:\n",
    "        df_studies = pd.concat([df_studies, df_studies_for_day]).sort_values(['Series Date', 'Start Time', 'Machine Group', 'SUID'])\n",
    "\n",
    "# save the newly extented studies to the studies file\n",
    "if len(days_to_process) > 0\n",
    "    df_studies.to_pickle(studies_save_path)\n",
    "\n",
    "df_studies_query = df_studies.query('Date >= \"{}\" & Date <= \"{}\"'.format(start_date, end_date)).copy()\n",
    "return df_studies_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some consensus on the studies descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "config['main']['start_date'] = '2019-01-01'\n",
    "config['main']['end_date'] = '2019-12-06'\n",
    "df_studies = load_transform_and_save_data_from_files(config)\n",
    "\n",
    "df_studies['short_descr'] = df_studies['Study Description'].str.lower().apply(lambda m: re.sub(r'[ _\\-^()\\+:\\.\\']', '', m))\n",
    "df_studies['Description'] = None\n",
    "\n",
    "# display(df_studies.groupby('Study Description')['Patient ID'].count().sort_values(ascending=False).iloc[0:10])\n",
    "# display(df_studies.groupby('short_descr')['Patient ID'].count().sort_values(ascending=False).iloc[0:10])\n",
    "\n",
    "for descr in config['description']:\n",
    "    for descr_pattern in config['description'][descr].split(','):\n",
    "        df_studies_match = df_studies[(df_studies['short_descr'].str.match('^' + descr_pattern + '$')) & (df_studies['Description'].isnull())]\n",
    "        if len(df_studies_match) == 0:\n",
    "            logging.info('descr [{:30s}] pattern \"{:30s}\": {:4d} matches'.format(descr, descr_pattern, len(df_studies_match)))\n",
    "        df_studies.loc[df_studies.index.isin(df_studies_match.index), 'Description'] = descr\n",
    "\n",
    "display(df_studies.groupby('Description')['Patient ID'].count().sort_values(ascending=False).iloc[0:10])\n",
    "df_no_descr = df_studies[df_studies['Description'].isnull()][['Patient ID', 'short_descr', 'Study Description']].groupby(['Study Description', 'short_descr'])['Patient ID'].count().sort_values(ascending=False)[0:15].reset_index()\n",
    "display(df_no_descr)\n",
    "df_no_descr = df_no_descr.drop(columns='Patient ID')\n",
    "df_no_descr['Study Description'] = df_no_descr['Study Description'].str.replace('_', ' ').str.replace(' \\(Adulte?\\)', '').str.replace('PET\\^. ', '').str.upper()\n",
    "abdo_rows = df_no_descr[df_no_descr['Study Description'].str.match('ABDOMEN')]\n",
    "df_no_descr.loc[df_no_descr.index.isin(abdo_rows.index), 'Study Description'] = df_no_descr.loc[df_no_descr.index.isin(abdo_rows.index), 'Study Description'].str.replace('ABDOMEN\\^. ', '') + ' ABDOMEN'\n",
    "for ind in df_no_descr.index:\n",
    "    print('{} = {}'.format(df_no_descr.loc[ind, 'Study Description'], df_no_descr.loc[ind, 'short_descr']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the description patterns from the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "descr_dict = {}\n",
    "for descr in config['description']:\n",
    "    descr_dict[descr] = []\n",
    "    for descr_pattern in config['description'][descr].split(','):\n",
    "        descr_dict[descr].append(descr_pattern)\n",
    "for key in sorted(descr_dict.keys()):\n",
    "    print('{} = {}'.format(key, ','.join(descr_dict[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the most common exams per machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "config['main']['start_date'] = '2019-01-01'\n",
    "config['main']['end_date'] = '2019-12-06'\n",
    "df_studies = load_transform_and_save_data_from_files(config)\n",
    "\n",
    "df_studies['short_descr'] = df_studies['Study Description'].str.lower().apply(lambda m: re.sub(r'[ _\\-^()\\+:\\.\\']', '', m))\n",
    "df_studies['Description'] = None\n",
    "\n",
    "# display(df_studies.groupby('Study Description')['Patient ID'].count().sort_values(ascending=False).iloc[0:10])\n",
    "# display(df_studies.groupby('short_descr')['Patient ID'].count().sort_values(ascending=False).iloc[0:10])\n",
    "\n",
    "for descr in config['description']:\n",
    "    for descr_pattern in config['description'][descr].split(','):\n",
    "        df_studies_match = df_studies[(df_studies['short_descr'].str.match('^' + descr_pattern + '$')) & (df_studies['Description'].isnull())]\n",
    "        if len(df_studies_match) == 0:\n",
    "            logging.debug('descr [{:30s}] pattern \"{:30s}\": {:4d} matches'.format(descr, descr_pattern, len(df_studies_match)))\n",
    "        df_studies.loc[df_studies.index.isin(df_studies_match.index), 'Description'] = descr\n",
    "\n",
    "        descr_dict = {}\n",
    "for descr in config['description']:\n",
    "    descr_dict[descr] = []\n",
    "    for descr_pattern in config['description'][descr].split(','):\n",
    "        descr_dict[descr].append(descr_pattern)\n",
    "    \n",
    "df_studies_clean = df_studies[df_studies['Machine Group'] != 'mixed cases'].copy()\n",
    "df_studies_clean['Machine'] = df_studies_clean['Machine Group'].str.replace('NoCT', '')\n",
    "df_descr_count = df_studies_clean.drop(columns='Machine Group').groupby(['Machine', 'Description'])['Patient ID'].count().reset_index()\n",
    "df_descr_count = df_descr_count.rename(columns={'Patient ID': 'Count'})[['Machine', 'Description', 'Count']].sort_values('Count', ascending=False)\n",
    "for machine in set(df_descr_count['Machine']):\n",
    "    print('[description_{}]'.format(machine.lower().replace(' ', '')))\n",
    "    for descr_key in sorted(descr_dict.keys()):\n",
    "        if len(df_descr_count.query('Machine == @machine and Description == @descr_key')['Count']) > 0 \\\n",
    "                and int(df_descr_count.query('Machine == @machine and Description == @descr_key')['Count']) > 10:\n",
    "            print('{} = {}'.format(descr_key, ','.join(descr_dict[descr_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(df_descr_count.query('Machine == @machine and Description == @descr_key')['Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the config and get the series manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "config['main']['start_date'] = '2019-01-07'\n",
    "config['main']['end_date'] = '2019-04-26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "config['main']['start_date'] = '2019-01-07'\n",
    "config['main']['end_date'] = '2019-04-26'\n",
    "df_series = load_data_from_files(config)\n",
    "\n",
    "indices_to_exclude = []\n",
    "logging.info('Found {} series before filtering description'.format(len(df_series)))\n",
    "for descr_pattern in config['retrieve']['series_descr_patterns_to_exclude'].split('\\n'):\n",
    "    to_exclude_rows = df_series['Series Description'].str.match(descr_pattern, case=False)\n",
    "    # gather all the indices\n",
    "    indices_to_exclude.append(to_exclude_rows[to_exclude_rows == True].index)\n",
    "# flatten the list\n",
    "indices_to_exclude = [index for indices in indices_to_exclude for index in indices.values]\n",
    "# if there is something to exclude, show a message and drop the rows\n",
    "if len(indices_to_exclude) > 0:\n",
    "    logging.info('Found {} series to exclude based on their description: \"{}\"'.format(len(indices_to_exclude),\n",
    "        '\", \"'.join(df_series.loc[indices_to_exclude]['Series Description'])))\n",
    "    df_series.drop(indices_to_exclude, inplace=True)\n",
    "logging.info('Found {} series after filtering description'.format(len(df_series)))\n",
    "\n",
    "# further filter out some Series that are not primary acquisitions (and do not contain any relevant time information)\n",
    "df_series = df_series[~df_series['Protocol Name'].isin(config['retrieve']['series_protocols_to_exclude'].split('\\n'))]\n",
    "logging.debug('Found {} series after filtering protocol names'.format(len(df_series)))\n",
    "\n",
    "#df_series = df_series[~df_series['Series Description'].isin(['Protocole patient', 'Enhancement curve'])]\n",
    "#df_series = df_series[df_series.Machine != 'syngo.via.VB30A']\n",
    "df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series[df_series.Machine == 'syngo.via.VB30A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the marking of the re-takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_series = mark_retakes(config, df_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series, df_count_series, df_count_studies, df_count_series_day, df_count_study_day, df_count_study_weekday = do_series_groupby(config, df_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check what happened in the \"mixed cases\" studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", 20): display(df_series[df_series['Machine Group'] == 'mixed cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_series[df_series['Machine Group'] == 'mixed cases']['Study Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some counting on different fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for field in ['Institution Name', 'Machine', 'Machine Group', 'Modality', 'Series Description', 'Study Description', 'Patient ID', 'i_take']:\n",
    "    logging.info('Number of *Series* groupped by \"{}\"'.format(field))\n",
    "    display(df_series.groupby(field)['SUID'].count())\n",
    "    logging.info('Number of *Studies* groupped by \"{}\"'.format(field))\n",
    "    display(df_series.groupby([field, 'SUID']).count().reset_index().groupby(field)['SUID'].count())\n",
    "    logging.info('='*160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out the start and end times of each study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studies = df_series.dropna().groupby('SUID').agg({\n",
    "    'Series Date': lambda x: '/'.join(set(x)),\n",
    "    'Start Time': 'min',\n",
    "    'End Time': 'max',\n",
    "    'Study Description': lambda x: '/'.join(set(x)),\n",
    "    'Machine Group': lambda x: '/'.join(set(x)),\n",
    "    'Modality': lambda x: '/'.join(set(x)),\n",
    "    'Institution Name': lambda x: '/'.join(set(x)),\n",
    "    'Protocol Name': lambda x: '/'.join(set(x))\n",
    "}).sort_values(['Series Date', 'Machine Group', 'Start Time', 'SUID'])\n",
    "studies_save_path = 'data/studies/studies_{}_{}.pkl'.format(config['main']['start_date'], config['main']['end_date']).replace('-', '')\n",
    "df_studies.to_pickle(studies_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studies = load_transform_and_save_data_from_files(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the series descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_studies['Study Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
