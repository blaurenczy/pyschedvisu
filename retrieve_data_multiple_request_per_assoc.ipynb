{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from scripts.main import *\n",
    "from scripts.retrieve_data import *\n",
    "from scripts.extract_data import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set the width of the notebook\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_logger()\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "retrieve_and_save_data_from_PACS(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_count = extract_transform_and_save_data_from_files(config)\n",
    "#display(df)\n",
    "display(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Start Time'].isnull())\n",
    "    | (df['End Time'].isnull())\n",
    "    | (df['Machine'] == '')\n",
    "    | (df['Institution Name'] == '')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to figure out why some series failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failed_with_info = fetch_info_for_series(config, df_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df, df_failed_with_info], sort=True)\n",
    "df2.drop_duplicates('Series Instance UID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rescued_series = df_failed_with_info.copy()\n",
    "df_failed_series = df_rescued_series[\n",
    "            (df_rescued_series['Start Time'].isnull())\n",
    "            | (df_rescued_series['End Time'].isnull())\n",
    "            | (df_rescued_series['Machine'] == '')\n",
    "            | (df_rescued_series['Institution Name'] == '')]\n",
    "# exclude series where some information could still not be gathered (e.g. no end time or no machine)\n",
    "df_rescued_series = df_rescued_series.loc[~df_rescued_series.index.isin(df_failed_series.index), :]\n",
    "df2 = pd.concat([df, df_rescued_series], sort=True)\n",
    "df_failed_series\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all studies and series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_studies = find_studies_for_day(config, config['main']['start_date'].replace('-', ''), ['PT', 'NM'])\n",
    "df_all_series = find_series_for_studies(config, df_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = df_all_series.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_series_subset = pd.concat([df_all_series[df_all_series.Modality == modality].head(n = 10) for modality in set(df_all_series.Modality)]).sort_values('Series Time').reset_index(drop=True)\n",
    "df_series_subset\n",
    "df_series = df_series_subset.copy()\n",
    "df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = fetch_info_for_series(config, df_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step before turing it to an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of field names to extract for each modality\n",
    "to_fetch_fields_ctpt = ['SeriesInstanceUID', 'PatientID', 'InstanceNumber', 'ManufacturerModelName',\n",
    "    'AcquisitionTime', 'Modality']\n",
    "to_fetch_fields_nm = ['SeriesInstanceUID', 'PatientID', 'InstanceNumber', 'ManufacturerModelName',\n",
    "    'AcquisitionTime', 'Modality', 'ActualFrameDuration', 'NumberOfFrames', '0x00540032', '0x00540052']\n",
    "\n",
    "# create modality specific masks of the DataFrame\n",
    "df_series_ctpt = df_series[df_series['Modality'].isin(['PT', 'CT'])]\n",
    "df_series_nm = df_series[df_series['Modality'] == 'NM']\n",
    "display(df_series_ctpt)\n",
    "display(df_series_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare the CT/PT queries for the first instance (first image)\n",
    "query_dicts_ctpt = list(df_series_ctpt.apply(lambda row: {\n",
    "    'SeriesDate': row['Series Date'],\n",
    "    'PatientID': row['Patient ID'],\n",
    "    'SeriesInstanceUID': row['Series Instance UID'],\n",
    "    'InstanceNumber': '1'\n",
    "}, axis=1))\n",
    "# prepare the CT/PT queries for the last instance (last image)\n",
    "df_last_frames = df_series_ctpt[df_series_ctpt['Number of Series Related Instances'] != '1']\n",
    "if len(df_last_frames) > 0:\n",
    "    query_dicts_ctpt.extend(\n",
    "        df_last_frames.apply(lambda row: {\n",
    "            'SeriesDate': row['Series Date'],\n",
    "            'PatientID': row['Patient ID'],\n",
    "            'SeriesInstanceUID': row['Series Instance UID'],\n",
    "            'InstanceNumber': row['Number of Series Related Instances']\n",
    "        }, axis=1))\n",
    "# fetch the CT/PT data\n",
    "logging.info('Getting CT/PT data ({} queries)'.format(len(query_dicts_ctpt)))\n",
    "df_info_ctpt = get_data(config, query_dicts_ctpt, to_fetch_fields_ctpt)\n",
    "\n",
    "# prepare the NM queries for the first instance (first image)\n",
    "query_dicts_nm = list(df_series_nm.apply(lambda row: {\n",
    "    'SeriesDate': row['Series Date'],\n",
    "    'PatientID': row['Patient ID'],\n",
    "    'SeriesInstanceUID': row['Series Instance UID']\n",
    "}, axis=1))\n",
    "# fetch the NM data\n",
    "logging.info('Getting NM data ({} queries)'.format(len(query_dicts_nm)))\n",
    "df_info_nm = get_data(config, query_dicts_nm, to_fetch_fields_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_save = df_series.copy()\n",
    "df_info_ctpt_save = df_info_ctpt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = df_series_save.copy()\n",
    "df_info_ctpt_save = df_info_ctpt_save.copy()\n",
    "\n",
    "# get the images with a single instance\n",
    "single_instances_UIDs = df_series.loc[\n",
    "    (df_series['Series Instance UID'].isin(df_info_ctpt['SeriesInstanceUID']))\\\n",
    "    & (df_series['Number of Series Related Instances'] == '1'), 'Series Instance UID']\n",
    "# duplicated them into the info DataFrame, so that they can also be merged together, as if there was two frames\n",
    "df_info_ctpt_single_inst_copies = df_info_ctpt[df_info_ctpt['SeriesInstanceUID'].isin(single_instances_UIDs)].copy()\n",
    "df_info_ctpt_single_inst_copies['InstanceNumber'] = 999999\n",
    "df_info_ctpt_extended = pd.concat([df_info_ctpt, df_info_ctpt_single_inst_copies], sort=True)\n",
    "\n",
    "# clean up the start times\n",
    "df_info_ctpt_extended.loc[:, 'AcquisitionTime'] = df_info_ctpt_extended.loc[:, 'AcquisitionTime']\\\n",
    "    .apply(lambda t: str(t).split('.')[0])\n",
    "# regroup the first and last instance rows on a single row\n",
    "df_info_ctpt_merged = df_info_ctpt_extended[df_info_ctpt_extended['InstanceNumber'] == 1]\\\n",
    "    .merge(df_info_ctpt_extended[df_info_ctpt_extended['InstanceNumber'] > 1],\n",
    "           on=['SeriesInstanceUID', 'PatientID', 'ManufacturerModelName', 'Modality'],\n",
    "           suffixes=['_start', '_end'])\n",
    "# rename the columns and keep the appropriate ones\n",
    "df_info_ctpt_clean = df_info_ctpt_merged.rename(columns={\n",
    "        'SeriesInstanceUID': 'Series Instance UID',\n",
    "        'PatientID': 'Patient ID',\n",
    "        'ManufacturerModelName': 'Machine',\n",
    "        'AcquisitionTime_start': 'Start Time',\n",
    "        'AcquisitionTime_end': 'End Time'})\\\n",
    "    .drop(columns=['InstanceNumber_start', 'InstanceNumber_end'])\n",
    "# merge the info into the series DataFrame\n",
    "df_series = df_series.merge(df_info_ctpt_clean, on=['Patient ID', 'Series Instance UID', 'Modality'],\n",
    "    how='outer')\n",
    "# keep only the relevant columns\n",
    "for f in ['Start Time', 'End Time', 'Machine']:\n",
    "    df_series[f] = df_series[f + '_y'].where(df_series[f + '_y'].notnull(), df_series[f + '_x'])\n",
    "    df_series.drop(columns=[f + '_y', f + '_x'], inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the start times\n",
    "df_info_nm.loc[:, 'AcquisitionTime'] = df_info_nm.loc[:, 'AcquisitionTime']\\\n",
    "    .apply(lambda t: str(t).split('.')[0])\n",
    "# use the AcquisitionTime as Start Time\n",
    "df_info_nm['Start Time'] = df_info_nm['AcquisitionTime']\n",
    "# call a function to calculate the End Times\n",
    "df_info_nm['End Time'] = df_info_nm.apply(get_NM_series_end_time, axis=1)\n",
    "# rename the columns and select the appropriate ones\n",
    "df_info_nm_clean = df_info_nm.rename(columns={\n",
    "        'SeriesInstanceUID': 'Series Instance UID',\n",
    "        'PatientID': 'Patient ID',\n",
    "        'ManufacturerModelName': 'Machine'})\\\n",
    "    [['Series Instance UID', 'Patient ID', 'Modality', 'Start Time', 'End Time', 'Machine']]\n",
    "# merge the info into the series DataFrame\n",
    "df_series = df_series.merge(df_info_nm_clean, on=['Patient ID', 'Series Instance UID', 'Modality'],\n",
    "    how='outer')\n",
    "# keep only the relevant columns\n",
    "for f in ['Start Time', 'End Time', 'Machine']:\n",
    "    df_series[f] = df_series[f + '_y'].where(df_series[f + '_y'].notnull(), df_series[f + '_x'])\n",
    "    df_series.drop(columns=[f + '_y', f + '_x'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmf = df_series[\n",
    "    (df_series['Start Time'].isnull())\n",
    "    | (df_series['End Time'].isnull())\n",
    "    | (df_series['Machine'] == '')\n",
    "    | (df_series['Institution Name'] == '')]\n",
    "dfmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmf2 = fetch_info_for_series(config, dfmf)\n",
    "dfmf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to query all images in one query data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch info for all \"first\" CT/PT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_ctpt_first = []\n",
    "while len(df_info_ctpt_first) == 0:\n",
    "    ds = Dataset()\n",
    "    ds.QueryRetrieveLevel = 'IMAGE'\n",
    "    ds.SeriesDate = '20191021'\n",
    "    ds.SeriesInstanceUID = list(set(df_ctpt['Series Instance UID']))\n",
    "    ds.PatientID =  list(set(df_ctpt['Patient ID']))\n",
    "    ds.InstanceNumber = '1'\n",
    "    ds.Modality = ['CT','PT']\n",
    "\n",
    "    # fields to fetch from the DICOM header\n",
    "    to_fetch_fields = ['SeriesInstanceUID', 'PatientID', 'InstanceNumber', 'ManufacturerModelName', 'AcquisitionTime',\n",
    "        'Modality', 'ImageType', 'ActualFrameDuration', 'NumberOfFrames', '0x00540032', '0x00540052']\n",
    "\n",
    "    # find information about this series by fetching some images\n",
    "    df_info_ctpt_first = get_data(config, [ds], to_fetch_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_info_ctpt_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch info for all \"last\" CT/PT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_last = []\n",
    "while len(df_info_last) == 0:\n",
    "    ds = Dataset()\n",
    "    ds.QueryRetrieveLevel = 'IMAGE'\n",
    "    ds.SeriesDate = '20191021'\n",
    "    ds.SeriesInstanceUID = list(set(df_ctpt['Series Instance UID']))\n",
    "    ds.PatientID =  list(set(df_ctpt['Patient ID']))\n",
    "    ds.InstanceNumber = list(set(df_ctpt['Number of Series Related Instances']))\n",
    "    ds.Modality = ['CT','PT']\n",
    "\n",
    "    # fields to fetch from the DICOM header\n",
    "    to_fetch_fields = ['SeriesInstanceUID', 'PatientID', 'InstanceNumber', 'ManufacturerModelName', 'AcquisitionTime',\n",
    "        'Modality', 'ImageType', 'ActualFrameDuration', 'NumberOfFrames', '0x00540032', '0x00540052']\n",
    "\n",
    "    # find information about this series by fetching some images\n",
    "    df_info_last = get_data(config, [ds], to_fetch_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_last.sort_values(by=\"InstanceNumber\").drop_duplicates(subset=[\"SeriesInstanceUID\"], keep=\"last\").reset_index()\n",
    "df_grouped.index += 1\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch info for all NM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_nm = []\n",
    "while len(df_info_nm) == 0:\n",
    "    ds = Dataset()\n",
    "    ds.QueryRetrieveLevel = 'IMAGE'\n",
    "    ds.SeriesDate = '20191021'\n",
    "    ds.SeriesInstanceUID = list(set(df_nm['Series Instance UID'][0:5]))\n",
    "    ds.PatientID =  list(set(df_nm['Patient ID'][0:5]))\n",
    "    ds.Modality = 'NM'\n",
    "\n",
    "    # fields to fetch from the DICOM header\n",
    "    to_fetch_fields = ['SeriesInstanceUID', 'PatientID', 'ManufacturerModelName', 'AcquisitionTime',\n",
    "        'Modality', 'ImageType', 'ActualFrameDuration', 'NumberOfFrames', '0x00540032', '0x00540052']\n",
    "\n",
    "    # find information about this series by fetching some images\n",
    "    df_info_nm = get_data(config, [ds], to_fetch_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Merge the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_series.merge(df_info.drop(columns='Modality').rename(columns={'SeriesInstanceUID': 'Series Instance UID'}), on='Series Instance UID', how='outer')\n",
    "#df_merged[['Series Date', 'Series Time', 'AcquisitionTime']]\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = []\n",
    "while len(df_info) == 0:\n",
    "    ds = Dataset()\n",
    "    ds.QueryRetrieveLevel = 'IMAGE'\n",
    "    ds.SeriesInstanceUID = df_series['Series Instance UID']\n",
    "    ds.PatientID =  df_series['Patient ID']\n",
    "    ds.Modality = 'NM'\n",
    "\n",
    "    # fields to fetch from the DICOM header\n",
    "    to_fetch_fields = ['SeriesInstanceUID', 'PatientID', 'InstanceNumber', 'ManufacturerModelName', 'AcquisitionTime',\n",
    "        'Modality', 'ImageType', 'ActualFrameDuration', 'NumberOfFrames', '0x00540032', '0x00540052']\n",
    "\n",
    "    # find information about this series by fetching some images\n",
    "    df_info = get_data(config, [ds], to_fetch_fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
