{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for retrieving data from PACS\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import configparser\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from IPython.core import display as ICD\n",
    "\n",
    "from pydicom.dataset import Dataset\n",
    "\n",
    "from scripts.run_all import run_all\n",
    "from scripts.retrieve_data_from_PACS import *\n",
    "\n",
    "#from pynetdicom import debug_logger\n",
    "#debug_logger()\n",
    "\n",
    "# set the width of display to infinite for all pandas DataFrame\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "# set the level of pynetdicom module's logger to ERROR, to avoid any logs\n",
    "logging.getLogger('pynetdicom').setLevel(logging.ERROR)\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the \"config\" object\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all 'PT' and 'NM' studies for a day\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studies = find_studies_for_day(config, config['main']['start_date'], ['PT', 'NM'])\n",
    "\n",
    "# filter out irrelevant studies\n",
    "df_studies = df_studies[df_studies['Patient ID'].str.match('^\\d+$')]\n",
    "df_studies = df_studies[~df_studies['Study Description'].isin(['EXTRINSEQUE'])]\n",
    "df_studies.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all series for the found studies and get their time ranges\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accepted_inst_names = ['centrehospitalieruniversitairevaudois', 'medecinenucleairechuvlausanne',\n",
    "                        'radiologiechuv', 'petctchuv']\n",
    "\n",
    "# go through each study and find its series\n",
    "logging.info('Going through {} studie(s)'.format(len(df_studies)))\n",
    "for i_study in range(len(df_studies)):\n",
    "    logging.debug('DataFrame row:\\n' + str(df_studies.loc[i_study, :]))\n",
    "    df_series = find_series_for_study(config, df_studies.loc[i_study, :])\n",
    "    \n",
    "    # filter for the institution name\n",
    "    inst_name = df_series.loc[0, 'Institution Name'].lower().replace(' ', '')\n",
    "    if inst_name not in accepted_inst_names:\n",
    "        logging.warning('Skipping study because it is not from CHUV (institution name: \"{}\")'.format(inst_name))\n",
    "    \n",
    "    # go through each study and find relevant information by fetching its image(s)\n",
    "    logging.info('Going through {} series'.format(len(df_series)))\n",
    "    for i_series in range(len(df_series)):\n",
    "        logging.debug('Series: ' + str(df_series.loc[i_series, :]))\n",
    "        row_info = fetch_info_for_series(config, df_series.loc[i_series, :])\n",
    "        \n",
    "        # abort processing for this series no data\n",
    "        if row_info is None:\n",
    "            logging.error('Skipping series {}: no data found.'.format(df_series.loc[i_series, 'Series Instance UID']))\n",
    "            continue\n",
    "\n",
    "        # copy the relevant parameters into the main DataFrame\n",
    "        df_series.loc[i_series, 'start_time'] = row_info['start_time']\n",
    "        df_series.loc[i_series, 'end_time'] = row_info['end_time']\n",
    "        df_series.loc[i_series, 'machine'] = row_info['machine']\n",
    "    \n",
    "    # remove redundant series\n",
    "    df_series = prunes_series_by_time_overlap(df_series)\n",
    "    \n",
    "    # create time ranges from the start/end times\n",
    "    time_ranges = []\n",
    "    for i_serie in range(len(df_series)):\n",
    "        time_ranges.append('{}-{}'.format(df_series.loc[i_serie, 'start_time'],\n",
    "                                          df_series.loc[i_serie, 'end_time']))\n",
    "    \n",
    "    # propagate back the time range and machine name information\n",
    "    df_studies.loc[i_study, 'machines'] = ','.join(list(set(df_series['machine'])))\n",
    "    df_studies.loc[i_study, 'time_ranges'] = ','.join(time_ranges)\n",
    "    df_studies.loc[i_study, 'overall_time_range'] = '{}-{}'.format(\n",
    "        df_series.iloc[0]['start_time'], df_series.iloc[-1]['end_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studies.to_pickle(config['main']['start_date'] + '.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further process the studies\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_studies.loc[:, ['Study Date', 'Study Description', 'Patient ID', 'machines']]\n",
    "df.columns = ['date', 'descr', 'pid', 'machine']\n",
    "df['start_time'] = df_studies.loc[:, 'Study Time']\n",
    "df['end_time'] = df_studies.loc[:, 'overall_time_range'].apply(lambda s: s.split('-')[1])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the machines to have some consensus\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out some Series that are not primary acquisitions (and do not contain any relevant time information)\n",
    "machine_names = ['Vision 600', 'Discovery 690', 'Millennium MPR', 'Intevo 16', 'Biograph20', 'Encore2']\n",
    "for machine_name in machine_names:\n",
    "    matching_rows = df['machine'].str.match('.*' + machine_name + '.*', case=False)\n",
    "    if matching_rows.sum() > 0:\n",
    "        logging.info('Found {} rows matching the name \"{}\":'.format(matching_rows.sum(), machine_name))\n",
    "    df.loc[matching_rows, 'machine'] = machine_name\n",
    "\n",
    "# replace the \"Encore2\" machine name to \"Intevo\", since it is the same machine\n",
    "df.loc[df['machine'] == 'Encore2', 'machine'] = 'Intevo 16'\n",
    "machine_names.remove('Encore2')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the descriptions to have some consensus\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out some Series that are not primary acquisitions (and do not contain any relevant time information)\n",
    "description_patterns = {'FDG Corps Entier': 'fdgcorpsentier', 'FDG Tronc': 'fdgtronc', 'Rb82 Coeur': 'rb82coeur',\n",
    "                       'FDG Abdomen TAP Veineux Corps Entier': 'abdomen1fdgtapveineuxpetcorpsentierflowadult',\n",
    "                       'Scintigraphie OctreoScan': 'scintioctreoscan'}\n",
    "for descr in description_patterns.keys():\n",
    "    matching_rows = df['descr'].str.lower().str.replace('[-_^ ()]', '').str\\\n",
    "        .match('.*' + description_patterns[descr] + '.*', case=False)\n",
    "    if matching_rows.sum() > 0:\n",
    "        logging.info('Found {} rows matching the name \"{}\":'.format(matching_rows.sum(), descr))\n",
    "    df.loc[matching_rows, 'descr'] = descr\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overlap for each machine\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine in machine_names:\n",
    "    logging.info('Checking overlap for machine \"{}\"'.format(machine))\n",
    "    df_machine = df[df['machine'] == machine]\n",
    "    df[df['machine'] == machine] = prunes_series_by_time_overlap(df_machine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save processed data\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(config['main']['start_date'] + '_processed.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
