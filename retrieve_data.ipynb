{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from IPython.core import display as ICD\n",
    "from scripts.main import *\n",
    "from scripts.retrieve_data_from_PACS import *\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "# set the level of pynetdicom module's logger to ERROR, to avoid any logs\n",
    "logging.getLogger('pynetdicom').setLevel(logging.ERROR)\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the \"config\" object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for retrieving data from PACS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_date = datetime.strptime(config['main']['start_date'], '%Y%m%d')\n",
    "end_date = datetime.strptime(config['main']['end_date'], '%Y%m%d')\n",
    "daterange = pd.date_range(start_date, end_date)\n",
    "for single_date in daterange:\n",
    "    logging.info(single_date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all 'PT' and 'NM' studies for a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_studies = find_studies_for_day(config, config['main']['start_date'], ['PT', 'NM'])\n",
    "df_studies.iloc[:, [0,1,2,3,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all series for the found studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_series = find_series_for_studies(config, df_studies)\n",
    "df_series.iloc[:, [0,1,2,3,4,5,10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through each series and find information about them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_series = fetch_info_for_series(config, df_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some statistics on the success / failure rates of fetching info for SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_for_fetching_series_info(df_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude series where no information could be gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the sub-DataFrame that do or do not have information\n",
    "df_with_info = df_series[~df_series['end_time'].isnull()]\n",
    "df_no_info = df_series[df_series['end_time'].isnull()]\n",
    "# count rows and display\n",
    "n, n_info, n_noinfo = len(df_series), len(df_with_info), len(df_no_info)\n",
    "logging.info('{:3d}/{:3d} rows with    info ({:.1f} %)'.format(n_info, n, 100 * n_info / n, ))\n",
    "logging.info('{:3d}/{:3d} rows without info ({:.1f} %)'.format(n_noinfo, n, 100 * n_noinfo / n))\n",
    "\n",
    "# filter out series where there is no information\n",
    "df_series = df_series[~df_series.start_time.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a summary of what machines are used in which institution names and modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = do_series_groupby(config, df_series)\n",
    "df_groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark the series as being a first or a second take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_series = mark_second_takes(config, df_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Show the series that have a second take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_series[df_series['Study Instance UID'].isin(df_series[df_series['i_take'] != 1]['Study Instance UID'])]\n",
    "df.iloc[:,[0,1,2,5,11,12,13,17]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a unique ID taking the second takes into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the relevant rows\n",
    "df_series_pruned = df_series.loc[indices_to_keep].sort_values(['Patient ID', 'Series Time'])\n",
    "\n",
    "# create a column of unique ID (including the information about second takes)\n",
    "df_series_pruned['UID'] = ''\n",
    "i_UID = 0\n",
    "\n",
    "# create a unique ID for the relevant series\n",
    "for ind in df_series_pruned.index:\n",
    "    UID = '{}-{}'.format(*df_series_pruned.loc[ind, ['Series Date', 'Patient ID']])\n",
    "    UID += '-{:04d}-A'.format(i_UID)\n",
    "    i_UID += 1\n",
    "    df_series_pruned.loc[ind, 'UID'] = UID\n",
    "\n",
    "df_series_pruned.iloc[:,[0,1,2,5,12,13,14,16,17]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the machines to have some consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_names = ['Vision 600', 'Discovery 690', 'Millennium MPR', 'Intevo 16', 'Discovery 670']\n",
    "\n",
    "\"\"\"\n",
    "Biograph64/vision PT\n",
    "discovery 690 PT\n",
    "*discovery 670 SPECT\n",
    "Millennium SPECT sans CT\n",
    "Encore2/Intevo SPECT\n",
    "\"\"\"\n",
    "\n",
    "for machine_name in machine_names:\n",
    "    matching_rows = df['Machine'].str.match('.*' + machine_name + '.*', case=False)\n",
    "    if matching_rows.sum() > 0:\n",
    "        logging.info('Found {} rows matching the name \"{}\":'.format(matching_rows.sum(), machine_name))\n",
    "    df.loc[matching_rows, 'Machine'] = machine_name\n",
    "\n",
    "# replace the \"Encore2\" machine name to \"Intevo\", since it is the same machine\n",
    "#df.loc[df['Machine'] == 'Encore2', 'Machine'] = 'Intevo 16'\n",
    "#machine_names.remove('Encore2')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the descriptions to have some consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_patterns = {'FDG Corps Entier': 'fdgcorpsentier', 'FDG Tronc': 'fdgtronc', 'Rb82 Coeur': 'rb82coeur',\n",
    "                       'FDG Abdomen TAP Veineux Corps Entier': 'abdomen1fdgtapveineuxpetcorpsentierflowadult',\n",
    "                       'Scintigraphie OctreoScan': 'scintioctreoscan', 'FDG WB Child': 'pet1petfdgwbflowchild'}\n",
    "for descr in description_patterns.keys():\n",
    "    matching_rows = df['descr'].str.lower().str.replace('[-_^ ()]', '').str\\\n",
    "        .match('.*' + description_patterns[descr] + '.*', case=False)\n",
    "    if matching_rows.sum() > 0:\n",
    "        logging.info('Found {} rows matching the name \"{}\":'.format(matching_rows.sum(), descr))\n",
    "    df.loc[matching_rows, 'descr'] = descr\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
